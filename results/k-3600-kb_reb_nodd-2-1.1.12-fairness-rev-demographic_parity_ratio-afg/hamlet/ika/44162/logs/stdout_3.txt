Sensitive groups ready!
Theory ready!
Theory:
step(normalization) :- true.
step(features) :- true.
step(mitigation) :- true.
step(rebalancing) :- true.
step(classification) :- true.
operator(normalization, power_transformer) :- true.
operator(normalization, robust_scaler) :- true.
operator(normalization, standard) :- true.
operator(normalization, minmax) :- true.
operator(features, select_k_best) :- true.
operator(features, pca) :- true.
operator(mitigation, corr_remover) :- true.
operator(mitigation, lfr) :- true.
operator(rebalancing, near_miss) :- true.
operator(rebalancing, smote) :- true.
operator(classification, knn) :- true.
operator(classification, nn) :- true.
operator(classification, rf) :- true.
hyperparameter(robust_scaler, with_centering, choice) :- true.
hyperparameter(robust_scaler, with_scaling, choice) :- true.
hyperparameter(standard, with_mean, choice) :- true.
hyperparameter(standard, with_std, choice) :- true.
hyperparameter(select_k_best, k, randint) :- true.
hyperparameter(pca, n_components, randint) :- true.
hyperparameter(corr_remover, alpha, choice) :- true.
hyperparameter(lfr, n_prototypes, choice) :- true.
hyperparameter(lfr, reconstruct_weight, choice) :- true.
hyperparameter(lfr, fairness_weight, choice) :- true.
hyperparameter(near_miss, n_neighbors, randint) :- true.
hyperparameter(smote, k_neighbors, randint) :- true.
hyperparameter(knn, n_neighbors, randint) :- true.
hyperparameter(knn, weights, choice) :- true.
hyperparameter(knn, metric, choice) :- true.
hyperparameter(nn, n_hidden_layers, choice) :- true.
hyperparameter(nn, n_neurons, choice) :- true.
hyperparameter(nn, activation, choice) :- true.
hyperparameter(nn, solver, choice) :- true.
hyperparameter(nn, alpha, choice) :- true.
hyperparameter(nn, learning_rate, choice) :- true.
hyperparameter(rf, n_estimators, choice) :- true.
hyperparameter(rf, max_depth, randint) :- true.
hyperparameter(rf, max_features, randint) :- true.
hyperparameter(rf, min_samples_split, randint) :- true.
hyperparameter(rf, max_leaf_nodes, randint) :- true.
hyperparameter(rf, bootstrap, choice) :- true.
hyperparameter(rf, criterion, choice) :- true.
domain(robust_scaler, with_centering, [true, false]) :- true.
domain(robust_scaler, with_scaling, [true, false]) :- true.
domain(standard, with_mean, [true, false]) :- true.
domain(standard, with_std, [true, false]) :- true.
domain(select_k_best, k, [1, 10]) :- true.
domain(pca, n_components, [1, 8]) :- true.
domain(corr_remover, alpha, [0.25, 0.5, 0.75, 1.0]) :- true.
domain(lfr, n_prototypes, [10, 50, 100, 200]) :- true.
domain(lfr, reconstruct_weight, [0.1, 0.5, 1.0, 2.0]) :- true.
domain(lfr, fairness_weight, [0.1, 0.5, 1.0, 2.0]) :- true.
domain(near_miss, n_neighbors, [1, 4]) :- true.
domain(smote, k_neighbors, [5, 8]) :- true.
domain(knn, n_neighbors, [3, 20]) :- true.
domain(knn, weights, [uniform, distance]) :- true.
domain(knn, metric, [minkowski, euclidean, manhattan]) :- true.
domain(nn, n_hidden_layers, [1, 5, 10, 20]) :- true.
domain(nn, n_neurons, [5, 10, 25, 50]) :- true.
domain(nn, activation, [logistic, tanh, relu]) :- true.
domain(nn, solver, [lbfgs, sgd, adam]) :- true.
domain(nn, alpha, [0.0001, 0.001, 0.01, 0.00001]) :- true.
domain(nn, learning_rate, [constant, invscaling, adaptive]) :- true.
domain(rf, n_estimators, [10, 25, 50, 75, 100]) :- true.
domain(rf, max_depth, [1, 5]) :- true.
domain(rf, max_features, [1, 4]) :- true.
domain(rf, min_samples_split, [2, 6]) :- true.
domain(rf, max_leaf_nodes, [2, 6]) :- true.
domain(rf, bootstrap, [true, false]) :- true.
domain(rf, criterion, [gini, entropy]) :- true.
dataset(compass) :- true.
metric(balanced_accuracy) :- true.
fairness_metric(demographic_parity_ratio) :- true.
sensitive_feature(sex, [0, 1]) :- true.
sensitive_feature(race, [0, 1, 2, 3, 4, 5]) :- true.
pipeline([Step_1_0], ZZ_0) :- (step(Step_1_0), '\\='(Step_1_0, classification), operator(classification, ZZ_0)).
pipeline([Step_1_1, Step_2_0], ZZ_1) :- (step(Step_1_1), step(Step_2_0), '\\='(Step_1_1, classification), '\\='(Step_2_0, classification), '\\='(Step_1_1, Step_2_0), operator(classification, ZZ_1)).
pipeline([Step_1_2, Step_2_1, Step_3_0], ZZ_2) :- (step(Step_1_2), step(Step_2_1), step(Step_3_0), '\\='(Step_1_2, classification), '\\='(Step_2_1, classification), '\\='(Step_3_0, classification), '\\='(Step_1_2, Step_2_1), '\\='(Step_1_2, Step_3_0), '\\='(Step_2_1, Step_3_0), operator(classification, ZZ_2)).
pipeline([Step_1_3, Step_2_2, Step_3_1, Step_4_0], ZZ_3) :- (step(Step_1_3), step(Step_2_2), step(Step_3_1), step(Step_4_0), '\\='(Step_1_3, classification), '\\='(Step_2_2, classification), '\\='(Step_3_1, classification), '\\='(Step_4_0, classification), '\\='(Step_1_3, Step_2_2), '\\='(Step_1_3, Step_3_1), '\\='(Step_1_3, Step_4_0), '\\='(Step_2_2, Step_3_1), '\\='(Step_2_2, Step_4_0), '\\='(Step_3_1, Step_4_0), operator(classification, ZZ_3)).
':=>'(p343835, sensitive_group([0])) :- true.
':=>'(p287613, sensitive_group([1])) :- true.
':=>'(p189430, sensitive_group([0])) :- true.
':=>'(p595736, sensitive_group([1])) :- true.
':=>'(p450090, sensitive_group([2])) :- true.
':=>'(p847576, sensitive_group([3])) :- true.
':=>'(p592710, sensitive_group([4])) :- true.
':=>'(p448078, sensitive_group([5])) :- true.
':=>'(p973628, sensitive_group([0, 0])) :- true.
':=>'(p786649, sensitive_group([0, 1])) :- true.
':=>'(p567512, sensitive_group([0, 2])) :- true.
':=>'(p757956, sensitive_group([0, 3])) :- true.
':=>'(p102382, sensitive_group([0, 4])) :- true.
':=>'(p789763, sensitive_group([0, 5])) :- true.
':=>'(p632425, sensitive_group([1, 0])) :- true.
':=>'(p555055, sensitive_group([1, 1])) :- true.
':=>'(p376040, sensitive_group([1, 2])) :- true.
':=>'(p506554, sensitive_group([1, 3])) :- true.
':=>'(p793423, sensitive_group([1, 4])) :- true.
':=>'(p778138, sensitive_group([1, 5])) :- true.

Checking Config
Exporting Config
Saving Graph
Exporting AutoML input
Exporting Space
Exporting Constraints
Input created for iteration Config(iteration=3, dataset=compass, metric=balanced_accuracy, fairnessMetric=demographic_parity_ratio, sensitiveFeatures=[sex, race], mode=max, batchSize=999999, timeBudget=900, seed=42)
Here is the standard output/error of the command:

84fae47c0782c3827d059d1f720bac5a202fb5192737dbc0e1158bcf21c2c7b7
Here is the standard output/error of the command:

Here is the standard output/error of the command:

WARNING:root:No module named 'rpy2': FairAdapt will be unavailable. To install, run:
pip install 'aif360[FairAdapt]'
INFO:flaml.tune.searcher.blendsearch:No low-cost partial config given to the search algorithm. For cost-frugal search, consider providing low-cost values for cost-related hps via 'low_cost_partial_config'. More info can be found at https://microsoft.github.io/FLAML/docs/FAQ#about-low_cost_partial_config-in-tune
AutoML: starting optimization.
58
success
{'classification': {'type': np.str_('RandomForestClassifier'), 'bootstrap': np.True_, 'criterion': np.str_('gini'), 'max_depth': 3, 'max_features': 4, 'max_leaf_nodes': 4, 'min_samples_split': 4, 'n_estimators': np.int64(10)}, 'normalization': {'type': np.str_('RobustScaler'), 'with_centering': np.False_, 'with_scaling': np.True_}, 'features': {'type': np.str_('FunctionTransformer')}, 'mitigation': {'type': np.str_('FunctionTransformer')}, 'prototype': np.str_('features_mitigation_rebalancing_normalization_classification'), 'rebalancing': {'type': np.str_('FunctionTransformer')}}
{'demographic_parity_ratio': np.float64(0.37682573936196967), 'balanced_accuracy': np.float64(0.6885218300491237), 'by_group': {'0_0': np.float64(0.72), '0_2': np.float64(0.61), '0_3': np.float64(0.38), '1_0': np.float64(1.0), '1_2': np.float64(0.68), '1_3': np.float64(0.63), '1_5': np.float64(0.53)}, 'status': 'success', 'total_time': 0.41300153732299805, 'fit_time': np.float64(0.038811779022216795), 'score_time': np.float64(0.007911920547485352), 'absolute_time': 1746697800.2553926, 'flatten_demographic_parity_ratio': '0.32_0.46_0.42_0.38_0.29', 'flatten_balanced_accuracy': '0.69_0.69_0.7_0.69_0.68'}
59
success
{'classification': {'type': np.str_('MLPClassifier'), 'activation': np.str_('tanh'), 'alpha': np.float64(0.0001), 'learning_rate': np.str_('adaptive'), 'n_hidden_layers': np.int64(10), 'n_neurons': np.int64(50), 'solver': np.str_('lbfgs')}, 'features': {'type': np.str_('PCA'), 'n_components': 1}, 'normalization': {'type': np.str_('StandardScaler'), 'with_mean': np.False_, 'with_std': np.False_}, 'rebalancing': {'type': np.str_('SMOTE'), 'k_neighbors': 8}, 'mitigation': {'type': np.str_('FunctionTransformer')}, 'prototype': np.str_('mitigation_features_normalization_rebalancing_classification')}
{'demographic_parity_ratio': np.float64(0.5637347400250878), 'balanced_accuracy': np.float64(0.642651370984652), 'by_group': {'0_0': np.float64(0.81), '0_2': np.float64(0.84), '0_3': np.float64(0.61), '1_0': np.float64(1.0), '1_2': np.float64(0.85), '1_3': np.float64(0.75), '1_5': np.float64(0.75)}, 'status': 'success', 'total_time': 377.72813987731934, 'fit_time': np.float64(75.33566298484803), 'score_time': np.float64(0.06866607666015626), 'absolute_time': 1746698178.0723627, 'flatten_demographic_parity_ratio': '0.56_0.46_0.78_0.63_0.4', 'flatten_balanced_accuracy': '0.65_0.65_0.64_0.64_0.64'}
60
success
{'classification': {'type': np.str_('RandomForestClassifier'), 'bootstrap': np.True_, 'criterion': np.str_('entropy'), 'max_depth': 2, 'max_features': 1, 'max_leaf_nodes': 6, 'min_samples_split': 6, 'n_estimators': np.int64(100)}, 'features': {'type': np.str_('PCA'), 'n_components': 4}, 'mitigation': {'type': np.str_('CorrelationRemover'), 'alpha': np.float64(0.75)}, 'rebalancing': {'type': np.str_('SMOTE'), 'k_neighbors': 6}, 'normalization': {'type': np.str_('FunctionTransformer')}, 'prototype': np.str_('mitigation_features_normalization_rebalancing_classification')}
{'demographic_parity_ratio': np.float64(0.4012343194502332), 'balanced_accuracy': np.float64(0.64430875009747), 'by_group': {'0_0': np.float64(0.6), '0_2': np.float64(0.61), '0_3': np.float64(0.49), '1_0': np.float64(0.99), '1_2': np.float64(0.75), '1_3': np.float64(0.73), '1_5': np.float64(0.73)}, 'status': 'success', 'total_time': 3.003821611404419, 'fit_time': np.float64(0.541492509841919), 'score_time': np.float64(0.014554452896118165), 'absolute_time': 1746698181.1859295, 'flatten_demographic_parity_ratio': '0.42_0.26_0.45_0.41_0.47', 'flatten_balanced_accuracy': '0.65_0.65_0.64_0.64_0.65'}
61
success
{'classification': {'type': np.str_('MLPClassifier'), 'activation': np.str_('relu'), 'alpha': np.float64(0.0001), 'learning_rate': np.str_('invscaling'), 'n_hidden_layers': np.int64(10), 'n_neurons': np.int64(50), 'solver': np.str_('lbfgs')}, 'features': {'type': np.str_('PCA'), 'n_components': 2}, 'mitigation': {'type': np.str_('LFR_wrapper'), 'fairness_weight': np.float64(0.5), 'n_prototypes': np.int64(200), 'reconstruct_weight': np.float64(1.0)}, 'normalization': {'type': np.str_('StandardScaler'), 'with_mean': np.True_, 'with_std': np.False_}, 'rebalancing': {'type': np.str_('NearMiss'), 'n_neighbors': 2}, 'prototype': np.str_('rebalancing_mitigation_features_normalization_classification')}
{'demographic_parity_ratio': np.float64(0.5098110834097702), 'balanced_accuracy': np.float64(0.6212407929984942), 'by_group': {'0_0': np.float64(0.73), '0_2': np.float64(0.84), '0_3': np.float64(0.55), '1_0': np.float64(1.0), '1_2': np.float64(0.84), '1_3': np.float64(0.73), '1_5': np.float64(0.72)}, 'status': 'success', 'total_time': 364.30587887763977, 'fit_time': np.float64(72.64392638206482), 'score_time': np.float64(0.06859750747680664), 'absolute_time': 1746698545.5838523, 'flatten_demographic_parity_ratio': '0.42_0.43_0.8_0.55_0.34', 'flatten_balanced_accuracy': '0.64_0.61_0.62_0.61_0.62'}
/usr/local/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide
  f = msb / msw
/usr/local/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide
  f = msb / msw
/usr/local/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide
  f = msb / msw
/usr/local/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide
  f = msb / msw
/usr/local/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide
  f = msb / msw
/usr/local/lib/python3.12/site-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide
  f = msb / msw
62
success
{'classification': {'type': np.str_('RandomForestClassifier'), 'bootstrap': np.True_, 'criterion': np.str_('entropy'), 'max_depth': 5, 'max_features': 2, 'max_leaf_nodes': 2, 'min_samples_split': 3, 'n_estimators': np.int64(25)}, 'features': {'type': np.str_('SelectKBest'), 'k': 1}, 'mitigation': {'type': np.str_('CorrelationRemover'), 'alpha': np.float64(0.25)}, 'normalization': {'type': np.str_('MinMaxScaler')}, 'prototype': np.str_('mitigation_normalization_features_rebalancing_classification'), 'rebalancing': {'type': np.str_('FunctionTransformer')}}
{'demographic_parity_ratio': np.float64(0.4630521209380952), 'balanced_accuracy': np.float64(0.6331615018254186), 'by_group': {'0_0': np.float64(0.71), '0_2': np.float64(0.69), '0_3': np.float64(0.46), '1_0': np.float64(1.0), '1_2': np.float64(0.71), '1_3': np.float64(0.65), '1_5': np.float64(0.64)}, 'status': 'success', 'total_time': 0.7110874652862549, 'fit_time': np.float64(0.09367485046386718), 'score_time': np.float64(0.007547569274902344), 'absolute_time': 1746698546.4002788, 'flatten_demographic_parity_ratio': '0.49_0.31_0.58_0.52_0.42', 'flatten_balanced_accuracy': '0.63_0.65_0.64_0.63_0.62'}
The result for {'classification': {'type': np.str_('KNeighborsClassifier'), 'metric': np.str_('manhattan'), 'n_neighbors': 8, 'weights': np.str_('distance')}, 'mitigation': {'type': np.str_('LFR_wrapper'), 'fairness_weight': np.float64(2.0), 'n_prototypes': np.int64(200), 'reconstruct_weight': np.float64(1.0)}, 'rebalancing': {'type': np.str_('SMOTE'), 'k_neighbors': 6}, 'features': {'type': np.str_('FunctionTransformer')}, 'normalization': {'type': np.str_('FunctionTransformer')}, 'prototype': np.str_('mitigation_features_rebalancing_normalization_classification')} was NaN

Something went wrong
Traceback (most recent call last):
  File "/home/automl/hamlet/objective.py", line 649, in objective
    raise Exception(f"The result for {config} was NaN")
Exception: The result for {'classification': {'type': np.str_('KNeighborsClassifier'), 'metric': np.str_('manhattan'), 'n_neighbors': 8, 'weights': np.str_('distance')}, 'mitigation': {'type': np.str_('LFR_wrapper'), 'fairness_weight': np.float64(2.0), 'n_prototypes': np.int64(200), 'reconstruct_weight': np.float64(1.0)}, 'rebalancing': {'type': np.str_('SMOTE'), 'k_neighbors': 6}, 'features': {'type': np.str_('FunctionTransformer')}, 'normalization': {'type': np.str_('FunctionTransformer')}, 'prototype': np.str_('mitigation_features_rebalancing_normalization_classification')} was NaN

63
fail
{'classification': {'type': np.str_('KNeighborsClassifier'), 'metric': np.str_('manhattan'), 'n_neighbors': 8, 'weights': np.str_('distance')}, 'mitigation': {'type': np.str_('LFR_wrapper'), 'fairness_weight': np.float64(2.0), 'n_prototypes': np.int64(200), 'reconstruct_weight': np.float64(1.0)}, 'rebalancing': {'type': np.str_('SMOTE'), 'k_neighbors': 6}, 'features': {'type': np.str_('FunctionTransformer')}, 'normalization': {'type': np.str_('FunctionTransformer')}, 'prototype': np.str_('mitigation_features_rebalancing_normalization_classification')}
{'demographic_parity_ratio': -inf, 'balanced_accuracy': np.float64(0.5026446389466382), 'by_group': {'0_0': np.float64(0.64), '0_2': np.float64(0.54), '0_3': np.float64(0.99), '1_0': np.float64(0.62), '1_2': np.float64(0.59), '1_3': np.float64(0.55), '1_5': np.float64(0.54)}, 'status': 'fail', 'total_time': 43.23473906517029, 'fit_time': np.float64(7.814307451248169), 'score_time': np.float64(0.4011200428009033), 'absolute_time': 1746698589.738081, 'flatten_demographic_parity_ratio': 'nan_0.62_0.49_0.2_0.27', 'flatten_balanced_accuracy': '0.5_0.5_0.51_0.5_0.51'}
64
success
{'classification': {'type': np.str_('KNeighborsClassifier'), 'metric': np.str_('euclidean'), 'n_neighbors': 4, 'weights': np.str_('uniform')}, 'normalization': {'type': np.str_('RobustScaler'), 'with_centering': np.False_, 'with_scaling': np.True_}, 'rebalancing': {'type': np.str_('NearMiss'), 'n_neighbors': 3}, 'features': {'type': np.str_('FunctionTransformer')}, 'mitigation': {'type': np.str_('FunctionTransformer')}, 'prototype': np.str_('features_mitigation_rebalancing_normalization_classification')}
{'demographic_parity_ratio': np.float64(0.17861317358639656), 'balanced_accuracy': np.float64(0.6330858214468031), 'by_group': {'0_0': np.float64(0.64), '0_2': np.float64(0.54), '0_3': np.float64(0.21), '1_0': np.float64(1.0), '1_2': np.float64(0.64), '1_3': np.float64(0.57), '1_5': np.float64(0.54)}, 'status': 'success', 'total_time': 1.9137487411499023, 'fit_time': np.float64(0.04858856201171875), 'score_time': np.float64(0.1485067367553711), 'absolute_time': 1746698591.7458012, 'flatten_demographic_parity_ratio': '0.13_0.07_0.4_0.07_0.22', 'flatten_balanced_accuracy': '0.62_0.63_0.64_0.65_0.63'}
65
success
{'classification': {'type': np.str_('MLPClassifier'), 'activation': np.str_('logistic'), 'alpha': np.float64(0.001), 'learning_rate': np.str_('constant'), 'n_hidden_layers': np.int64(10), 'n_neurons': np.int64(10), 'solver': np.str_('lbfgs')}, 'features': {'type': np.str_('PCA'), 'n_components': 3}, 'rebalancing': {'type': np.str_('NearMiss'), 'n_neighbors': 2}, 'mitigation': {'type': np.str_('FunctionTransformer')}, 'normalization': {'type': np.str_('FunctionTransformer')}, 'prototype': np.str_('normalization_features_rebalancing_mitigation_classification')}
{'demographic_parity_ratio': np.float64(0.5168425306141937), 'balanced_accuracy': np.float64(0.6468090586971951), 'by_group': {'0_0': np.float64(0.78), '0_2': np.float64(0.85), '0_3': np.float64(0.57), '1_0': np.float64(1.0), '1_2': np.float64(0.83), '1_3': np.float64(0.75), '1_5': np.float64(0.74)}, 'status': 'success', 'total_time': 134.6439962387085, 'fit_time': np.float64(26.87294521331787), 'score_time': np.float64(0.011557579040527344), 'absolute_time': 1746698726.483048, 'flatten_demographic_parity_ratio': '0.56_0.4_0.64_0.62_0.36', 'flatten_balanced_accuracy': '0.65_0.65_0.65_0.64_0.65'}
AutoML: optimization done.
AutoML: miner done.
AutoML: export done.
Here is the standard output/error of the command:

Here is the standard output/error of the command:

Here is the standard output/error of the command:

hamlet_524550693
AutoML execution ended
